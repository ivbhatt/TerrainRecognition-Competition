{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sync_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFQrjSpmH14o",
        "outputId": "c3132f9c-5ce8-4bf8-dc1e-4e2e6f5b8d65"
      },
      "source": [
        "# GDrive mount (required only if being run on GDrive)\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63GqFaBKuTK"
      },
      "source": [
        "# importing dependencies\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgvWnGoIH9bD"
      },
      "source": [
        "##### PLEASE SET THESE CAREFULLY refer :instructions.txt\n",
        "INPUT_DIR = \"/gdrive/Shareddrives/DLNN_ProjC1/input/ECE542_sp2021_Project_TerrainRecognition\"\n",
        "OUTPUT_DIR_TRAIN = \"/gdrive/Shareddrives/DLNN_ProjC1/output/sync_data_ishan/train\"\n",
        "OUTPUT_DIR_TEST = \"/gdrive/Shareddrives/DLNN_ProjC1/output/sync_data_ishan/test\"\n",
        "#####\n",
        "\n",
        "\n",
        "# Based on directory structure provided by teaching staff\n",
        "TRAIN_DIR = os.path.join(INPUT_DIR, \"TrainingData\")\n",
        "TEST_DIR = os.path.join(INPUT_DIR, \"TestData\")\n",
        "\n",
        "\n",
        "#Constants\n",
        "ATTRIBUTE_NAMES = [\"accel_x\", \"accel_y\", \"accel_z\", \"gyro_x\", \"gyro_y\", \"gyro_z\"]\n",
        "TIME = [\"TIME\"]\n",
        "CLASS = [\"CLASS\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mao-Z0_z0pHd"
      },
      "source": [
        "# function to synchronize the data. Logic explained in report \n",
        "def sync_data(file_x, file_x_time, file_y, file_y_time, IN_DIR=\".\", OUT_DIR=\".\"):\n",
        "  \n",
        "  # finding the prefix for this group of files\n",
        "  prefix = file_x[:15]\n",
        "  print(\"Processing:\", prefix, end = \" \")\n",
        "  \n",
        "  # loading data in memory\n",
        "  x = pd.read_csv(os.path.join(IN_DIR, file_x), names = ATTRIBUTE_NAMES)\n",
        "  x_time = pd.read_csv(os.path.join(IN_DIR, file_x_time), names = TIME)\n",
        "  \n",
        "  y = pd.DataFrame(data = np.ones((x.shape[0], ), dtype = np.uint8)*-1, columns = CLASS)\n",
        "  if file_y != None:\n",
        "    y = pd.read_csv(os.path.join(IN_DIR, file_y), names = CLASS)\n",
        "\n",
        "  y_time = pd.read_csv(os.path.join(IN_DIR, file_y_time), names = TIME)\n",
        "\n",
        "\n",
        "  # column to store class in x (initialized to -1)\n",
        "  df_CLASS = np.ones(shape = (x_time.shape[0],), dtype=np.uint8)*-1\n",
        "  x[\"CLASS\"] = df_CLASS\n",
        "\n",
        "  # column to store synchronized time (initialized to -1)\n",
        "  df_yTIME = np.ones_like(x_time[\"TIME\"])*-1\n",
        "  x[\"yTIME\"] = df_yTIME\n",
        "  x[\"xTIME\"] = x_time[\"TIME\"]\n",
        "\n",
        "\n",
        "\n",
        "  # we first replace the x_times to the closest possible y_times (Greedy appraoch)\n",
        "  y_time_pointer = 0\n",
        "  y_time_temp = y_time.iloc[y_time_pointer][\"TIME\"]\n",
        "  next_y_time_temp = y_time.iloc[min(y_time_pointer+1, y_time.shape[0]-1)][\"TIME\"]\n",
        "\n",
        "  # the closest times for which y is available is stored in syncTIME column\n",
        "  for i in range(x.shape[0]):\n",
        "    x_time_temp = x.iloc[i][\"xTIME\"]\n",
        "    if(abs(y_time_temp - x_time_temp) < abs(next_y_time_temp - x_time_temp)):\n",
        "      x.at[i,\"yTIME\"] = y_time_temp\n",
        "    else:\n",
        "      x.at[i,\"yTIME\"] = next_y_time_temp\n",
        "      y_time_pointer +=1;\n",
        "      y_time_temp = next_y_time_temp \n",
        "      next_y_time_temp = y_time.iloc[min(y_time_pointer+1, y_time.shape[0]-1)][\"TIME\"]\n",
        "\n",
        "\n",
        "  print(\".\", end = \"\")\n",
        "\n",
        "  # now using the sync_time we join x and y (we also keep the sync_time attribute for debug)\n",
        "  for i in range(x.shape[0]):\n",
        "    time_stamp = x.iloc[i][\"yTIME\"]\n",
        "    time_index = np.where(y_time[\"TIME\"] == time_stamp)[0][0]\n",
        "    x.at[i, \"CLASS\"] = y.iloc[time_index][\"CLASS\"]\n",
        "\n",
        "\n",
        "  ## Down-sampling everything to 10Hz\n",
        "\n",
        "\n",
        "\n",
        "  file_x_sync = prefix + \"x_sync.csv\"\n",
        "  x.to_csv(os.path.join(OUT_DIR, file_x_sync), header= False, index = False)\n",
        "  print(\".\", end = \"\")\n",
        "    \n",
        "  print(\"DONE\")\n",
        "  \n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78NzfbWtPhuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc87114-980a-48e9-f67f-fe458646e401"
      },
      "source": [
        "# calling the above function for all of train data\n",
        "# no need to call on test data (since we dont have test labels, lol)\n",
        "prefixes = {filename[:15] for filename in os.listdir(os.path.join(INPUT_DIR, TRAIN_DIR))}\n",
        "for prefix in sorted(prefixes):\n",
        "  sync_data(prefix+\"_x.csv\", prefix+\"_x_time.csv\", prefix+\"_y.csv\", prefix+\"_y_time.csv\", IN_DIR= TRAIN_DIR, OUT_DIR=OUTPUT_DIR_TRAIN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing: subject_001_01_ ..DONE\n",
            "Processing: subject_001_02_ ..DONE\n",
            "Processing: subject_001_03_ ..DONE\n",
            "Processing: subject_001_04_ ..DONE\n",
            "Processing: subject_001_05_ ..DONE\n",
            "Processing: subject_001_06_ ..DONE\n",
            "Processing: subject_001_07_ ..DONE\n",
            "Processing: subject_001_08_ ..DONE\n",
            "Processing: subject_002_01_ ..DONE\n",
            "Processing: subject_002_02_ ..DONE\n",
            "Processing: subject_002_03_ ..DONE\n",
            "Processing: subject_002_04_ ..DONE\n",
            "Processing: subject_002_05_ ..DONE\n",
            "Processing: subject_003_01_ ..DONE\n",
            "Processing: subject_003_02_ ..DONE\n",
            "Processing: subject_003_03_ ..DONE\n",
            "Processing: subject_004_01_ ..DONE\n",
            "Processing: subject_004_02_ ..DONE\n",
            "Processing: subject_005_01_ ..DONE\n",
            "Processing: subject_005_02_ ..DONE\n",
            "Processing: subject_005_03_ ..DONE\n",
            "Processing: subject_006_01_ ..DONE\n",
            "Processing: subject_006_02_ ..DONE\n",
            "Processing: subject_006_03_ ..DONE\n",
            "Processing: subject_007_01_ ..DONE\n",
            "Processing: subject_007_02_ ..DONE\n",
            "Processing: subject_007_03_ ..DONE\n",
            "Processing: subject_007_04_ ..DONE\n",
            "Processing: subject_008_01_ ..DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWmapWfrBlwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc5bf19-fc7a-4330-ccfe-4927e79505cd"
      },
      "source": [
        "# calling the above function for all of test data\n",
        "# no need to call on test data (since we dont have test labels, lol)\n",
        "prefixes = {filename[:15] for filename in os.listdir(os.path.join(INPUT_DIR, TEST_DIR))}\n",
        "for prefix in sorted(prefixes):\n",
        "  sync_data(prefix+\"_x.csv\", prefix+\"_x_time.csv\", None, prefix+\"_y_time.csv\", IN_DIR= TEST_DIR, OUT_DIR=OUTPUT_DIR_TEST)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing: subject_009_01_ ..DONE\n",
            "Processing: subject_010_01_ ..DONE\n",
            "Processing: subject_011_01_ ..DONE\n",
            "Processing: subject_012_01_ ..DONE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}